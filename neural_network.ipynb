{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "bWhdgtMU11IH"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn import preprocessing\n",
        "from datetime import datetime\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "USE_GPU = True\n",
        "dtype = torch.float32 # we will be using float throughout this tutorial\n",
        "device = torch.device('cuda') if (USE_GPU and torch.cuda.is_available()) else torch.device('cpu')\n",
        "\n",
        "# Constant to control how frequently we print train loss\n",
        "print_every = 100\n",
        "print('using device:', device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TdHe8e0621xG",
        "outputId": "0eb78901-62b9-4a84-9772-8bf7c2831225"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/gdrive', force_remount=True)\n",
        "\n",
        "  FOLDERNAME = '2A/HACKATON'\n",
        "  %cd /content/gdrive/My\\ Drive/$FOLDERNAME\n",
        "except ImportError:\n",
        "  pass"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2xtwx3lR3Oh-",
        "outputId": "bf120cdb-94a2-4ebd-9edd-531f638edfa7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            "/content/gdrive/My Drive/2A/HACKATON\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 56
        },
        "id": "E1_Cr77T3Xr1",
        "outputId": "6f3348c9-e2da-4407-f438-7671ac12a1c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/gdrive/My Drive/2A/HACKATON'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = pd.read_csv('processed_waiting_times_train.csv')"
      ],
      "metadata": {
        "id": "72P9ilnw2pvS"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out_features = max(df_train[\"WAIT_TIME_IN_2H\"]) + 1\n",
        "print(out_features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2L28LCbW4Riw",
        "outputId": "e51cde8a-dd99-45a0-a854-c7e1754ec34a"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = df_train[\"WAIT_TIME_IN_2H\"]\n",
        "print(y)\n",
        "\n",
        "x = df_train\n",
        "x.drop([\"WAIT_TIME_IN_2H\"], axis=1, inplace=True)\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mGhFy__h5J_v",
        "outputId": "c06045cb-7ddc-46fa-80a9-20cdd616804e"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0        6\n",
            "1        5\n",
            "2        7\n",
            "3        2\n",
            "4        2\n",
            "        ..\n",
            "37013    2\n",
            "37014    4\n",
            "37015    2\n",
            "37016    9\n",
            "37017    4\n",
            "Name: WAIT_TIME_IN_2H, Length: 37018, dtype: int64\n",
            "       ADJUST_CAPACITY  DOWNTIME  CURRENT_WAIT_TIME  TIME_TO_PARADE_1  \\\n",
            "0            -0.660639 -0.168584          -0.240147          1.271664   \n",
            "1            -0.660639 -0.168584           0.468341         -0.620346   \n",
            "2            -0.527907 -0.168584           0.822585          1.271664   \n",
            "3            -0.726608 -0.168584          -0.594390         -1.010215   \n",
            "4            -1.033079 -0.168584          -0.594390          1.271664   \n",
            "...                ...       ...                ...               ...   \n",
            "37013         1.356085 -0.168584           0.468341         -0.815281   \n",
            "37014        -0.527907 -0.168584          -0.594390         -0.712080   \n",
            "37015         1.356085 -0.168584          -0.594390         -1.033149   \n",
            "37016         1.356085 -0.168584           0.468341         -0.723547   \n",
            "37017        -1.033079 -0.168584          -0.240147          1.271664   \n",
            "\n",
            "       TIME_TO_PARADE_2  TIME_TO_NIGHT_SHOW       PC1       PC2       PC3  \\\n",
            "0              0.443823            1.275582 -1.703404 -0.561189 -0.521895   \n",
            "1              0.443823           -0.740186 -0.983224 -3.370968  1.688497   \n",
            "2              0.443823            1.275582  1.971007  0.491093 -0.446060   \n",
            "3              0.443823           -0.903406 -1.153047 -1.460163  0.761943   \n",
            "4              0.443823            1.275582  0.644351  2.261365  0.670276   \n",
            "...                 ...                 ...       ...       ...       ...   \n",
            "37013          0.443823           -0.764669  2.474459 -0.242590 -1.250092   \n",
            "37014         -2.056777           -0.789152  1.451294 -0.740837 -0.309993   \n",
            "37015         -2.883588           -0.936050 -3.211167 -0.929818 -1.205296   \n",
            "37016          0.443823           -0.780991  0.588498  2.259265  2.034889   \n",
            "37017          0.443823            1.275582 -0.546490  1.411215  1.077576   \n",
            "\n",
            "            PC4  ...     38     39     40     41     42     43     44     45  \\\n",
            "0      0.099553  ...  False  False  False  False  False  False  False  False   \n",
            "1      0.822912  ...  False  False  False  False  False  False  False  False   \n",
            "2     -1.375623  ...  False  False  False  False  False  False  False  False   \n",
            "3      0.267117  ...  False  False  False  False  False   True  False  False   \n",
            "4      0.539488  ...  False  False  False  False  False  False  False  False   \n",
            "...         ...  ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
            "37013  0.433454  ...  False  False  False  False  False  False  False  False   \n",
            "37014 -0.850829  ...  False  False  False  False  False  False  False  False   \n",
            "37015 -0.270431  ...  False  False  False  False  False   True  False  False   \n",
            "37016 -0.714293  ...  False  False  False  False  False  False  False  False   \n",
            "37017 -0.678336  ...  False  False  False  False  False  False  False  False   \n",
            "\n",
            "          46     47  \n",
            "0      False  False  \n",
            "1      False  False  \n",
            "2      False  False  \n",
            "3      False  False  \n",
            "4      False  False  \n",
            "...      ...    ...  \n",
            "37013  False  False  \n",
            "37014  False  False  \n",
            "37015  False  False  \n",
            "37016  False  False  \n",
            "37017  False  False  \n",
            "\n",
            "[37018 rows x 84 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "in_features = len(x.columns)\n",
        "print(in_features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1YrZF6M9hlw",
        "outputId": "a1065710-50fe-4529-f3d3-2040bab40f09"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "84\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.15, random_state=0)"
      ],
      "metadata": {
        "id": "nzKKu29x4waD"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = x_train.astype(float)\n",
        "x_test = x_test.astype(float)\n",
        "y_train = y_train.astype(int)\n",
        "y_test = y_test.astype(int)"
      ],
      "metadata": {
        "id": "HAhM_e1d7eGt"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = torch.tensor(x_train.values, dtype=torch.float64, device=device)\n",
        "x_test = torch.tensor(x_test.values, dtype=torch.float64, device=device)\n",
        "y_train = torch.tensor(y_train.values, dtype=torch.int64, device=device)\n",
        "y_test = torch.tensor(y_test.values, dtype=torch.int64, device=device)"
      ],
      "metadata": {
        "id": "LHup4Yqk8zB9"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#y_train = F.one_hot(y_train, out_features)\n",
        "#y_test = F.one_hot(y_test, out_features)\n",
        "print(y_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SJ2zSQy49mmn",
        "outputId": "add6573a-70bf-4be2-a2a9-17a4602674b9"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([31465])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "train_dataset = TensorDataset(x_train, y_train)\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(in_features, 512),\n",
        "    nn.ReLU(),\n",
        "    nn.BatchNorm1d(512),\n",
        "    nn.Linear(512, 512),\n",
        "    nn.ReLU(),\n",
        "    nn.BatchNorm1d(512),\n",
        "    nn.Linear(512, 1024),\n",
        "    nn.ReLU(),\n",
        "    nn.BatchNorm1d(1024),\n",
        "    nn.Linear(1024, 1024),\n",
        "    nn.ReLU(),\n",
        "    nn.BatchNorm1d(1024),\n",
        "    nn.Linear(1024, 1024),\n",
        "    nn.ReLU(),\n",
        "    nn.BatchNorm1d(1024),\n",
        "    nn.Linear(1024, 1024),\n",
        "    nn.ReLU(),\n",
        "    nn.BatchNorm1d(1024),\n",
        "    nn.Linear(1024, 512),\n",
        "    nn.ReLU(),\n",
        "    nn.BatchNorm1d(512),\n",
        "    nn.Linear(512, out_features),\n",
        ")\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=1e-2)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "model.to(device=device)\n",
        "\n",
        "model.train()\n",
        "num_epochs = 100\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  for inputs, targets in train_loader:\n",
        "      inputs = inputs.to(device=device, dtype=torch.float)\n",
        "      outputs = model(inputs)\n",
        "\n",
        "      loss = criterion(outputs, targets)\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "\n",
        "      optimizer.step()\n",
        "  print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n"
      ],
      "metadata": {
        "id": "AQZJtbcW4V9q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "914adafc-b3c2-4638-fb84-fd47de19e4d6"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/100], Loss: 1.9011\n",
            "Epoch [2/100], Loss: 2.0605\n",
            "Epoch [3/100], Loss: 1.6330\n",
            "Epoch [4/100], Loss: 1.1920\n",
            "Epoch [5/100], Loss: 1.9710\n",
            "Epoch [6/100], Loss: 1.4943\n",
            "Epoch [7/100], Loss: 1.0544\n",
            "Epoch [8/100], Loss: 1.1339\n",
            "Epoch [9/100], Loss: 1.2143\n",
            "Epoch [10/100], Loss: 0.6633\n",
            "Epoch [11/100], Loss: 1.3209\n",
            "Epoch [12/100], Loss: 1.0501\n",
            "Epoch [13/100], Loss: 0.7992\n",
            "Epoch [14/100], Loss: 0.8406\n",
            "Epoch [15/100], Loss: 0.5765\n",
            "Epoch [16/100], Loss: 0.8804\n",
            "Epoch [17/100], Loss: 0.4926\n",
            "Epoch [18/100], Loss: 0.7237\n",
            "Epoch [19/100], Loss: 0.7034\n",
            "Epoch [20/100], Loss: 1.2619\n",
            "Epoch [21/100], Loss: 0.4673\n",
            "Epoch [22/100], Loss: 0.4920\n",
            "Epoch [23/100], Loss: 0.6902\n",
            "Epoch [24/100], Loss: 0.7469\n",
            "Epoch [25/100], Loss: 0.6837\n",
            "Epoch [26/100], Loss: 0.2812\n",
            "Epoch [27/100], Loss: 0.5655\n",
            "Epoch [28/100], Loss: 0.3508\n",
            "Epoch [29/100], Loss: 0.1349\n",
            "Epoch [30/100], Loss: 0.6631\n",
            "Epoch [31/100], Loss: 0.3938\n",
            "Epoch [32/100], Loss: 0.3893\n",
            "Epoch [33/100], Loss: 0.3246\n",
            "Epoch [34/100], Loss: 0.4512\n",
            "Epoch [35/100], Loss: 0.2481\n",
            "Epoch [36/100], Loss: 0.3327\n",
            "Epoch [37/100], Loss: 0.4874\n",
            "Epoch [38/100], Loss: 0.0732\n",
            "Epoch [39/100], Loss: 0.1862\n",
            "Epoch [40/100], Loss: 0.1059\n",
            "Epoch [41/100], Loss: 0.2648\n",
            "Epoch [42/100], Loss: 0.1460\n",
            "Epoch [43/100], Loss: 0.2374\n",
            "Epoch [44/100], Loss: 0.4690\n",
            "Epoch [45/100], Loss: 0.1507\n",
            "Epoch [46/100], Loss: 0.3077\n",
            "Epoch [47/100], Loss: 0.1395\n",
            "Epoch [48/100], Loss: 0.2609\n",
            "Epoch [49/100], Loss: 0.1171\n",
            "Epoch [50/100], Loss: 0.1794\n",
            "Epoch [51/100], Loss: 0.0987\n",
            "Epoch [52/100], Loss: 0.1471\n",
            "Epoch [53/100], Loss: 0.3400\n",
            "Epoch [54/100], Loss: 0.1563\n",
            "Epoch [55/100], Loss: 0.1668\n",
            "Epoch [56/100], Loss: 0.1029\n",
            "Epoch [57/100], Loss: 0.2225\n",
            "Epoch [58/100], Loss: 0.0615\n",
            "Epoch [59/100], Loss: 0.1959\n",
            "Epoch [60/100], Loss: 0.1281\n",
            "Epoch [61/100], Loss: 0.0743\n",
            "Epoch [62/100], Loss: 0.4476\n",
            "Epoch [63/100], Loss: 0.3102\n",
            "Epoch [64/100], Loss: 0.0945\n",
            "Epoch [65/100], Loss: 0.2508\n",
            "Epoch [66/100], Loss: 0.1052\n",
            "Epoch [67/100], Loss: 0.0533\n",
            "Epoch [68/100], Loss: 0.0356\n",
            "Epoch [69/100], Loss: 0.1837\n",
            "Epoch [70/100], Loss: 0.1351\n",
            "Epoch [71/100], Loss: 0.0246\n",
            "Epoch [72/100], Loss: 0.1432\n",
            "Epoch [73/100], Loss: 0.3743\n",
            "Epoch [74/100], Loss: 0.0537\n",
            "Epoch [75/100], Loss: 0.1478\n",
            "Epoch [76/100], Loss: 0.1094\n",
            "Epoch [77/100], Loss: 0.1623\n",
            "Epoch [78/100], Loss: 0.0165\n",
            "Epoch [79/100], Loss: 0.5288\n",
            "Epoch [80/100], Loss: 0.0760\n",
            "Epoch [81/100], Loss: 0.1603\n",
            "Epoch [82/100], Loss: 0.3062\n",
            "Epoch [83/100], Loss: 0.0340\n",
            "Epoch [84/100], Loss: 0.0338\n",
            "Epoch [85/100], Loss: 0.0993\n",
            "Epoch [86/100], Loss: 0.0338\n",
            "Epoch [87/100], Loss: 0.0981\n",
            "Epoch [88/100], Loss: 0.0803\n",
            "Epoch [89/100], Loss: 0.1338\n",
            "Epoch [90/100], Loss: 0.3341\n",
            "Epoch [91/100], Loss: 0.0833\n",
            "Epoch [92/100], Loss: 0.0477\n",
            "Epoch [93/100], Loss: 0.0135\n",
            "Epoch [94/100], Loss: 0.0103\n",
            "Epoch [95/100], Loss: 0.0301\n",
            "Epoch [96/100], Loss: 0.1837\n",
            "Epoch [97/100], Loss: 0.0620\n",
            "Epoch [98/100], Loss: 0.0457\n",
            "Epoch [99/100], Loss: 0.1965\n",
            "Epoch [100/100], Loss: 0.1639\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SbyBxnlD_g5p",
        "outputId": "6dc7798e-b46f-454a-bdf5-92cc4f3395bc"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_test = x_test.to(device=device, dtype=torch.float)\n",
        "y_hat = torch.argmax(model(x_test), dim=1)\n",
        "print(y_hat)\n",
        "\n",
        "def accuracy(y_hat, y_test):\n",
        "  return torch.sum(y_hat == y_test) / len(y_hat)\n",
        "\n",
        "print(accuracy(y_hat, y_test))\n",
        "\n",
        "print(np.sqrt(torch.sum((5*y_hat - 5*y_test)**2 ).cpu()) / len(y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XGw6vPTWLfD2",
        "outputId": "1a20fa1b-6d79-4c56-9b24-15d7ef435641"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([7, 9, 1,  ..., 7, 7, 1], device='cuda:0')\n",
            "tensor(0.5485, device='cuda:0')\n",
            "tensor(0.1191, dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#VALIDATION"
      ],
      "metadata": {
        "id": "oqIMAmxzU4gI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_val = pd.read_csv('processed_waiting_times_val.csv')\n",
        "dates = x_val[\"DATETIME\"]\n",
        "entities = x_val[\"ENTITY_DESCRIPTION_SHORT\"]\n",
        "x_val.drop([\"DATETIME\", \"ENTITY_DESCRIPTION_SHORT\"], axis=1, inplace=True)\n",
        "\n",
        "x_val = x_val.astype(float)\n",
        "x_val = torch.tensor(x_val.values, dtype=torch.float64, device=device)\n",
        "x_val = x_val.to(device=device, dtype=torch.float)"
      ],
      "metadata": {
        "id": "5dpZuMWHRWf_"
      },
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_hat = torch.argmax(model(x_val), dim=1)\n",
        "\n",
        "clean_y_hat = np.array((y_hat).cpu())*5\n",
        "print(len(clean_y_hat))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D0U7TXbYSglJ",
        "outputId": "0daabf4d-ec29-4385-db86-afa66f2c237a"
      },
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2444\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res_df = pd.DataFrame(list(zip(clean_y_hat, entities, dates, [\"Validation\" for _ in range(len(dates))])), columns=[\"y_pred\", \"ENTITY_DESCRIPTION_SHORT\", \"DATETIME\", \"KEY\"])\n",
        "res_df.to_csv('/content/gdrive/MyDrive/2A/HACKATON/res.csv', index=False)"
      ],
      "metadata": {
        "id": "ZA55KDECTRoD"
      },
      "execution_count": 152,
      "outputs": []
    }
  ]
}